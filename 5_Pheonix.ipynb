{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import search\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/bucket/projects'\n",
    "projdir = '2019_07_11_JUMP-CP'\n",
    "batchname = '2020_11_16_Scope1_PE'\n",
    "#platename = 'CPBroadPhenixNCP4__NC_BIN2_3P_2020-10-09T16_58_02-Measurement1'\n",
    "outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plates)\n",
    "#fpath = os.path.join(batchpath, 'images', platename, 'Images')\n",
    "#batchpath =  os.path.join(path, projdir, batchname)\n",
    "#plates = fpath.split('/')[-2].split('__')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixC1PlaneP1 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixC1PlaneP2 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixC1PlaneP3 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixC1PlaneP4 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixCP1 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixCP2 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixCP3 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixCP4 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNC1PlaneP1 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNC1PlaneP2 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNC1PlaneP3 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNC1PlaneP4 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNCP1 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNCP2 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNCP3 is created\n",
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixNCP4 already exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(*args):\n",
    "    \n",
    "    plist = [f for f in os.listdir(os.path.join(path, projdir, batchname, 'images'))]\n",
    "\n",
    "    for p in plist:\n",
    "\n",
    "        fpath = os.path.join(path, projdir, batchname, 'images', p, 'Images')\n",
    "\n",
    "        plates = fpath.split('/')[-2].split('__')[0]\n",
    "\n",
    "        outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plates)\n",
    "\n",
    "\n",
    "        def makedirectory():\n",
    "\n",
    "            try:\n",
    "                os.makedirs(outpath)\n",
    "                \n",
    "                print(\"Directory\", outpath, \"is created\")\n",
    "                \n",
    "            except IOError:\n",
    "                \n",
    "                print(\"Directory\", outpath, \"already exists\")\n",
    "\n",
    "        directory = makedirectory()\n",
    "\n",
    "        df = load_data() ## Applying function\n",
    "\n",
    "        df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)\n",
    "\n",
    "        loaddataillum = load_data_with_illum(*loaddata)\n",
    "\n",
    "        loaddataillum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv')\n",
    "        \n",
    "        \n",
    "    \n",
    "    return\n",
    "\n",
    "    \n",
    "main(path, projdir, batchname)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    lst=[]\n",
    "\n",
    "    for i, image in enumerate(os.listdir(fpath)):\n",
    "\n",
    "        imgpath = os.path.join(fpath, image)\n",
    "\n",
    "        if imgpath.endswith(\"tiff\"):\n",
    "\n",
    "            head, tail = os.path.split(imgpath)\n",
    "\n",
    "            lst.append(tail)\n",
    "            \n",
    "            \n",
    "    channels = {'ch1':\"OrigDNA\",\n",
    "    'ch2':\"OrigER\",\n",
    "    'ch3':\"OrigRNA\",\n",
    "    'ch4':\"OrigWGPhalloidin\",\n",
    "    'ch5':\"OrigMito\",\n",
    "    }\n",
    "\n",
    "    keys = list(channels.keys())\n",
    "    values = list(channels.values())\n",
    "\n",
    "\n",
    "    ch1 = [s for s in lst if 'ch1' in s]\n",
    "    ch2 = [s for s in lst if 'ch2' in s]\n",
    "    ch3 = [s for s in lst if 'ch3' in s]\n",
    "    ch4 = [s for s in lst if 'ch4' in s]\n",
    "    ch5 = [s for s in lst if 'ch5' in s]\n",
    "    \n",
    "\n",
    "    zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "    df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "    path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "    df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "    wellname = df['FileName_OrigDNA'].tolist()\n",
    "\n",
    "\n",
    "    pattern = re.compile(\"r(?P<row>\\d+)c(?P<column>\\d+)f(?P<site>\\d+)p(?P<zplane>\\d+)-ch(?P<channelnumber>\\d+)\")\n",
    "\n",
    "\n",
    "    ## apply this regrex to all the imagelist\n",
    "\n",
    "    match = [pattern.match(i) for i in wellname]\n",
    "    row = [r.group(\"row\") for r in match]\n",
    "    col= [c.group(\"column\") for c in match]\n",
    "    site= [f.group(\"site\") for f in match]\n",
    "    zplane= [int(s.group(\"zplane\")) for s in match]\n",
    "    channel= [ch.group(\"channelnumber\") for ch in match]\n",
    "\n",
    "    ## Defining Well names\n",
    "\n",
    "    rc = [r+c for r, c in zip(row, col)]\n",
    "\n",
    "    well_assignment= {'01' : \"A\",'02': \"B\",'03':\"C\",'04':\"D\",\n",
    "                      '05': \"E\",'06':\"F\",'07':\"G\",'08':\"H\",\n",
    "                      '09':\"I\",'10':\"J\",'11':\"K\",'12':\"L\",\n",
    "                      '13':\"M\",'14':\"N\",'15':\"O\",'16':\"P\"\n",
    "    }\n",
    "\n",
    "    well = [well_assignment.get(i[0:2])+i[2:] for i in rc]\n",
    "\n",
    "    df['Metadata_Well'] = well\n",
    "    df['Metadata_Site'] = site\n",
    "    df['Metadata_Plate'] = plates\n",
    "    df['Metadata_ZPlane'] = zplane\n",
    "    \n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "             'FileName_OrigER', 'PathName_OrigER',\n",
    "             'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "             'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "             'FileName_OrigMito', 'PathName_OrigMito',\n",
    "             'Metadata_Plate','Metadata_Well', \n",
    "            'Metadata_Site','Metadata_ZPlane']\n",
    "    \n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_with_illum(*args):\n",
    "\n",
    "    df['FileName_IllumDNA'] = plates+'_IllumDNA.npy'\n",
    "    \n",
    "    df['PathName_IllumDNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumER'] = plates+'_IllumER.npy'\n",
    "    \n",
    "    df['PathName_IllumER'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumRNA'] = plates+'_IllumRNA.npy'\n",
    "    \n",
    "    df['PathName_IllumRNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumWGPhalloidin'] = plates+'_IllumWGPhalloidin.npy'\n",
    "    \n",
    "    df['PathName_IllumWGPhalloidin'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumMito'] = plates+'_IllumMito.npy'\n",
    "    \n",
    "    df['PathName_IllumMito'] = os.path.join(batchpath, 'illum', plates)\n",
    "\n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "                 'FileName_OrigER', 'PathName_OrigER',\n",
    "                 'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "                 'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "                 'FileName_OrigMito', 'PathName_OrigMito',\n",
    "                 'Metadata_Plate','Metadata_Well', \n",
    "                'Metadata_Site', 'Metadata_ZPlane','FileName_IllumDNA', 'PathName_IllumDNA', \n",
    "                'FileName_IllumER', 'PathName_IllumER', \n",
    "                'FileName_IllumRNA', 'PathName_IllumRNA',\n",
    "                'FileName_IllumWGPhalloidin', 'PathName_IllumWGPhalloidin',\n",
    "                'FileName_IllumMito', 'PathName_IllumMito']\n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
