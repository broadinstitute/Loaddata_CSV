{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import search\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/bucket/projects'\n",
    "projdir = '2019_07_11_JUMP-CP-pilots'\n",
    "batchname = '2020_10_27_Scope1_YokogawaJapan'\n",
    "batchpath=os.path.join(path, projdir,batchname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b57fd8f0a73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdirec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "direc, sub, files = os.walk(os.path.join(path, projdir, batchname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plist = [f for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "\n",
    "plist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = [f for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "\n",
    "platelist = []\n",
    "\n",
    "\n",
    "outpath_list = []\n",
    "\n",
    "\n",
    "for p in plist:\n",
    "\n",
    "\n",
    "    pl = p.split(\"-\")\n",
    "    \n",
    "    plate = '_'.join(pl)\n",
    "    \n",
    "    \n",
    "    outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plate)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def makedirectory():\n",
    "\n",
    "#         try:\n",
    "#             os.makedirs(outpath)\n",
    "\n",
    "#             print(\"Directory\", outpath, \"is created\")\n",
    "\n",
    "#         except IOError:\n",
    "\n",
    "#             print(\"Directory\", outpath, \"already exists\")\n",
    "\n",
    "#     directory = makedirectory()\n",
    "    \n",
    "    \n",
    "    platelist.append(plate)\n",
    "    \n",
    "    outpath_list.append(outpath)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117014-3D-2x2x1-singleplane-10x_20201026_113115/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117014-3D-2x2x1-singleplane-20x_20201026_113115/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117033-3D-2x2x1-dpc-20x_20201023_151718/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117033-3D-2x2x1-singleplane-20x_20201015_161709/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117056-2x2x1-20x_20201022_110522/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117056-3D-2x2x1-20x_20201022_173956/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059-40x_20201013_155609/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059_20X_20201010_140319/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO01177034-20x_20201020_164856/PECCU']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plist_path = [os.path.join(path, projdir, batchname, f, 'PECCU') for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "\n",
    "plist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Channel mapping\n",
    "\n",
    "# channels = {'ch1':\"OrigDNA\",\n",
    "#     'ch2':\"OrigER\",\n",
    "#     'ch3':\"OrigActin_Golgi\",\n",
    "#     'ch4':\"OrigMito\",\n",
    "#     'ch5':\"OrigNucleoli\",\n",
    "#     'ch6':\"OrigBrightField\",\n",
    "#     }\n",
    "\n",
    "channels = {'ch1':\"OrigDNA\",\n",
    "    'ch2':\"OrigER\",\n",
    "    'ch3':\"OrigActin_Golgi\",\n",
    "    'ch4':\"OrigMito\",\n",
    "    'ch5':\"OrigNucleoli\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117033-3D-2x2x1-singleplane-20x_20201015_161709/PECCU\n",
      "/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/workspace/load_data_csv/2020_11_16_Scope1_YokogawaUS/BRO0117033_3D_2x2x1_singleplane_20x_20201015_161709\n",
      "BRO0117033_3D_2x2x1_singleplane_20x_20201015_161709\n"
     ]
    }
   ],
   "source": [
    "fpath = plist_path[3]\n",
    "\n",
    "outpath = outpath_list[3]\n",
    "\n",
    "\n",
    "\n",
    "plate = os.path.split(outpath)[-1]\n",
    "\n",
    "print(fpath)\n",
    "print(outpath)\n",
    "print(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(channels):\n",
    "    \n",
    "    lst = []\n",
    "\n",
    "    for i, image in enumerate(os.listdir(fpath)):\n",
    "    \n",
    "        imgpath = os.path.join(fpath, image)\n",
    "\n",
    "\n",
    "        if imgpath.endswith(\"tif\"):\n",
    "\n",
    "                head, tail = os.path.split(imgpath)\n",
    "                \n",
    "                if \"PECCU\" in tail:\n",
    "            \n",
    "        \n",
    "                    lst.append(tail)\n",
    "\n",
    "\n",
    "        keys = list(channels.keys())\n",
    "        values = list(channels.values())\n",
    "\n",
    "\n",
    "        ch1 = [s for s in lst if 'C01.' in s]\n",
    "        ch2 = [s for s in lst if 'C02.' in s]\n",
    "        ch3 = [s for s in lst if 'C03.' in s]\n",
    "        ch4 = [s for s in lst if 'C04.' in s]\n",
    "        ch5 = [s for s in lst if 'C05.' in s]\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "        zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "        df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "        path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "        df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "        wellname = df['FileName_OrigDNA'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "        pattern = re.compile(\".+_(?P<Well>\\w+)_.+F0(?P<site>\\d+)\")\n",
    "\n",
    "\n",
    "\n",
    "        match = [pattern.match(i) for i in wellname]\n",
    "        well = [r.group(\"Well\") for r in match]\n",
    "        site= [f.group(\"site\") for f in match]\n",
    "\n",
    "        site_0= [f.group(\"site\") for f in match]\n",
    "\n",
    "        site = [(lambda x: x.strip('0') if isinstance(x,str) and len(x) != 1 else x)(x) for x in site_0]\n",
    "\n",
    "\n",
    "\n",
    "        df['Metadata_Well'] = well\n",
    "        df['Metadata_Site'] = site\n",
    "        df['Metadata_Plate'] = plate\n",
    "\n",
    "\n",
    "\n",
    "        colnames = ['FileName_'+values[0], 'PathName_'+values[0],\n",
    "                    'FileName_'+values[1], 'PathName_'+values[1],\n",
    "                    'FileName_'+values[2], 'PathName_'+values[2],\n",
    "                    'FileName_'+values[3], 'PathName_'+values[3],\n",
    "                    'FileName_'+values[4], 'PathName_'+values[4],\n",
    "                    'Metadata_Plate','Metadata_Well', \n",
    "                    'Metadata_Site']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "   \n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "df = load_data(channels) \n",
    "\n",
    "df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_illum(channels):\n",
    "    \n",
    "    illum_channels = list(channels.values())\n",
    "    \n",
    "\n",
    "\n",
    "    illum = [s.replace(\"Orig\", \"Illum\") for s in illum_channels]\n",
    "\n",
    "    df['FileName_'+illum[0]] = plate + '_' + illum[0] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[0]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[1]] = plate + '_' + illum[1] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[1]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[2]] = plate + '_' + illum[2] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[2]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[3]] = plate + '_' + illum[3] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[3]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[4]] = plate + '_' + illum[4] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[4]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "       \n",
    "    return df.reindex()\n",
    "\n",
    "illum = load_data_with_illum(channels)\n",
    "\n",
    "illum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
