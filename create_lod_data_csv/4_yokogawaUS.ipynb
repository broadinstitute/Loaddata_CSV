{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import search\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/bucket/projects'\n",
    "projdir = '2019_07_11_JUMP-CP-pilots'\n",
    "batchname = '2020_11_16_Scope1_YokogawaUS'\n",
    "batchpath=os.path.join(path, projdir,batchname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRO0117014_3D_2x2x1_singleplane_10x_20201026_113115',\n",
       " 'BRO0117014_3D_2x2x1_singleplane_20x_20201026_113115',\n",
       " 'BRO0117033_3D_2x2x1_dpc_20x_20201023_151718',\n",
       " 'BRO0117033_3D_2x2x1_singleplane_20x_20201015_161709',\n",
       " 'BRO0117056_2x2x1_20x_20201022_110522',\n",
       " 'BRO0117056_3D_2x2x1_20x_20201022_173956',\n",
       " 'BRO0117059_40x_20201013_155609',\n",
       " 'BRO0117059_20X_20201010_140319',\n",
       " 'BRO01177034_20x_20201020_164856']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plist = [f for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "\n",
    "platelist = []\n",
    "\n",
    "\n",
    "outpath_list = []\n",
    "\n",
    "\n",
    "for p in plist:\n",
    "\n",
    "\n",
    "    pl = p.split(\"-\")\n",
    "    \n",
    "    plate = '_'.join(pl)\n",
    "    \n",
    "    \n",
    "    outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def makedirectory():\n",
    "\n",
    "        try:\n",
    "            os.makedirs(outpath)\n",
    "\n",
    "            print(\"Directory\", outpath, \"is created\")\n",
    "\n",
    "        except IOError:\n",
    "\n",
    "            print(\"Directory\", outpath, \"already exists\")\n",
    "\n",
    "    directory = makedirectory()\n",
    "    \n",
    "    \n",
    "    platelist.append(plate)\n",
    "    \n",
    "    outpath_list.append(outpath)\n",
    "        \n",
    "platelist       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117014-3D-2x2x1-singleplane-10x_20201026_113115/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117014-3D-2x2x1-singleplane-20x_20201026_113115/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117033-3D-2x2x1-dpc-20x_20201023_151718/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117033-3D-2x2x1-singleplane-20x_20201015_161709/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117056-2x2x1-20x_20201022_110522/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117056-3D-2x2x1-20x_20201022_173956/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059-40x_20201013_155609/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059_20X_20201010_140319/PECCU',\n",
       " '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO01177034-20x_20201020_164856/PECCU']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plist_path = [os.path.join(path, projdir, batchname, f, 'AssayPlate_PerkinElmer_CellCarrier-384') for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "plist_path = [os.path.join(path, projdir, batchname, f, 'PECCU') for f in os.listdir(os.path.join(path, projdir, batchname))]\n",
    "plist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Channel mapping\n",
    "\n",
    "# channels = {'ch1':\"OrigDNA\",\n",
    "#     'ch2':\"OrigER\",\n",
    "#     'ch3':\"OrigActin_Golgi\",\n",
    "#     'ch4':\"OrigMito\",\n",
    "#     'ch5':\"OrigNucleoli\"\n",
    "#     }\n",
    "\n",
    "channels = {'ch1':\"OrigDNA\",\n",
    "    'ch2':\"OrigER\",\n",
    "    'ch3':\"OrigActin_Golgi\",\n",
    "    'ch4':\"OrigMito\",\n",
    "    'ch5':\"OrigNucleoli\",\n",
    "    'ch6':\"OrigBrightField\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059-40x_20201013_155609/AssayPlate_PerkinElmer_CellCarrier-384/\n",
      "/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/workspace/load_data_csv/2020_11_16_Scope1_YokogawaUS/BRO0117059_40x_20201013_155609\n",
      "BRO0117059_40x_20201013_155609\n"
     ]
    }
   ],
   "source": [
    "#fpath = plist_path[4]\n",
    "\n",
    "fpath = \"/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_YokogawaUS/BRO0117059-40x_20201013_155609/AssayPlate_PerkinElmer_CellCarrier-384/\"\n",
    "\n",
    "outpath = outpath_list[6]\n",
    "\n",
    "\n",
    "\n",
    "plate = os.path.split(outpath)[-1]\n",
    "\n",
    "print(fpath)\n",
    "print(outpath)\n",
    "print(plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "for i, image in enumerate(os.listdir(fpath)):\n",
    "\n",
    "    imgpath = os.path.join(fpath, image)\n",
    "\n",
    "\n",
    "    if imgpath.endswith(\"tif\"):\n",
    "\n",
    "            head, tail = os.path.split(imgpath)\n",
    "\n",
    "            if \"AssayPlate_PerkinElmer_CellCarrier\" in tail:\n",
    "\n",
    "\n",
    "                lst.append(tail)\n",
    "\n",
    "\n",
    "    keys = list(channels.keys())\n",
    "    values = list(channels.values())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = [s for s in lst if 'C01.' in s]\n",
    "ch2 = [s for s in lst if 'C02.' in s]\n",
    "ch3 = [s for s in lst if 'C03.' in s]\n",
    "ch4 = [s for s in lst if 'C04.' in s]\n",
    "ch5 = [s for s in lst if 'C05.' in s]\n",
    "ch6 = [s for s in lst if 'C06.' and 'Z08' in s]\n",
    "\n",
    "\n",
    "zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5, ch6))\n",
    "\n",
    "#zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "wellname = df['FileName_OrigDNA'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "pattern = re.compile(\".+384_(?P<Well>\\w+)_.+F0(?P<site>\\d+)\")\n",
    "\n",
    "match = [pattern.match(i) for i in wellname]\n",
    "well = [r.group(\"Well\") for r in match]\n",
    "site_0= [f.group(\"site\") for f in match]\n",
    "\n",
    "site = [(lambda x: x.strip('0') if isinstance(x,str) and len(x) != 1 else x)(x) for x in site_0]  # removing zero infornt of the string\n",
    "\n",
    "\n",
    "\n",
    "df['Metadata_Well'] = well\n",
    "df['Metadata_Site'] = site\n",
    "df['Metadata_Plate'] = plate\n",
    "\n",
    "\n",
    "\n",
    "colnames = ['FileName_'+values[0], 'PathName_'+values[0],\n",
    "            'FileName_'+values[1], 'PathName_'+values[1],\n",
    "            'FileName_'+values[2], 'PathName_'+values[2],\n",
    "            'FileName_'+values[3], 'PathName_'+values[3],\n",
    "            'FileName_'+values[4], 'PathName_'+values[4],\n",
    "            'FileName_'+values[5], 'PathName_'+values[5],\n",
    "            'Metadata_Plate','Metadata_Well', \n",
    "            'Metadata_Site']\n",
    "\n",
    "df.reindex(columns=colnames)\n",
    "\n",
    "df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(channels):\n",
    "    \n",
    "    lst = []\n",
    "\n",
    "    for i, image in enumerate(os.listdir(fpath)):\n",
    "    \n",
    "        imgpath = os.path.join(fpath, image)\n",
    "\n",
    "\n",
    "        if imgpath.endswith(\"tif\"):\n",
    "\n",
    "                head, tail = os.path.split(imgpath)\n",
    "                \n",
    "                if \"AssayPlate_PerkinElmer_CellCarrier\" in tail:\n",
    "            \n",
    "        \n",
    "                    lst.append(tail)\n",
    "\n",
    "\n",
    "        keys = list(channels.keys())\n",
    "        values = list(channels.values())\n",
    "\n",
    "\n",
    "        ch1 = [s for s in lst if 'C01.' in s]\n",
    "        ch2 = [s for s in lst if 'C02.' in s]\n",
    "        ch3 = [s for s in lst if 'C03.' in s]\n",
    "        ch4 = [s for s in lst if 'C04.' in s]\n",
    "        ch5 = [s for s in lst if 'C05.' in s]\n",
    "        ch6 = [s for s in lst if 'C06.' and 'Z08' in s]\n",
    "\n",
    "\n",
    "        zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5, ch6))\n",
    "        \n",
    "        #zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "        path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "        df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "        wellname = df['FileName_OrigDNA'].tolist()\n",
    "        \n",
    "\n",
    "\n",
    "        pattern = re.compile(\".+384_(?P<Well>\\w+)_.+F0(?P<site>\\d+)\")\n",
    "\n",
    "        match = [pattern.match(i) for i in wellname]\n",
    "        well = [r.group(\"Well\") for r in match]\n",
    "        site_0= [f.group(\"site\") for f in match]\n",
    "        \n",
    "        site = [(lambda x: x.strip('0') if isinstance(x,str) and len(x) != 1 else x)(x) for x in site_0]  # removing zero infornt of the string\n",
    "\n",
    "        \n",
    "\n",
    "        df['Metadata_Well'] = well\n",
    "        df['Metadata_Site'] = site\n",
    "        df['Metadata_Plate'] = plate\n",
    "\n",
    "\n",
    "\n",
    "        colnames = ['FileName_'+values[0], 'PathName_'+values[0],\n",
    "                    'FileName_'+values[1], 'PathName_'+values[1],\n",
    "                    'FileName_'+values[2], 'PathName_'+values[2],\n",
    "                    'FileName_'+values[3], 'PathName_'+values[3],\n",
    "                    'FileName_'+values[4], 'PathName_'+values[4],\n",
    "                    'FileName_'+values[5], 'PathName_'+values[5],\n",
    "                    'Metadata_Plate','Metadata_Well', \n",
    "                    'Metadata_Site']\n",
    "        \n",
    "        \n",
    "#         colnames = ['FileName_'+values[0], 'PathName_'+values[0],\n",
    "#                     'FileName_'+values[1], 'PathName_'+values[1],\n",
    "#                     'FileName_'+values[2], 'PathName_'+values[2],\n",
    "#                     'FileName_'+values[3], 'PathName_'+values[3],\n",
    "#                     'FileName_'+values[4], 'PathName_'+values[4],\n",
    "#                     'Metadata_Plate','Metadata_Well', \n",
    "#                     'Metadata_Site']\n",
    "\n",
    "   \n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "df = load_data(channels) \n",
    "\n",
    "df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_illum(channels):\n",
    "\n",
    "    illum_channels = list(channels.values())\n",
    "\n",
    "    illum = [s.replace(\"Orig\", \"Illum\") for s in illum_channels]\n",
    "\n",
    "    df['FileName_'+illum[0]] = plate + '_' + illum[0] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[0]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[1]] = plate + '_' + illum[1] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[1]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[2]] = plate + '_' + illum[2] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[2]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[3]] = plate + '_' + illum[3] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[3]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "\n",
    "    df['FileName_'+illum[4]] = plate + '_' + illum[4] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[4]] = os.path.join(batchpath, 'illum', plate)\n",
    "\n",
    "    df['FileName_'+illum[5]] = plate + '_' + illum[5] + '.npy'\n",
    "\n",
    "    df['PathName_'+illum[5]] = os.path.join(batchpath, 'illum', plate)\n",
    "    \n",
    "    return df.reindex()\n",
    "\n",
    "illum = load_data_with_illum(channels)\n",
    "\n",
    "illum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
