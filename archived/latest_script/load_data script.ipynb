{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import search\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main(*args):\n",
    "    \n",
    "#     plist = [f for f in os.listdir(os.path.join(path, projdir, batchname, 'images'))]\n",
    "\n",
    "#     for p in plist:\n",
    "\n",
    "#         fpath = os.path.join(path, projdir, batchname, 'images', p, 'Images')\n",
    "\n",
    "#         plates = fpath.split('/')[-2].split('__')[0]\n",
    "\n",
    "#         outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plates)\n",
    "\n",
    "\n",
    "#         def makedirectory():\n",
    "\n",
    "#             try:\n",
    "#                 os.makedirs(outpath)\n",
    "#                 print(\"Directory\", outpath, \"is created\")\n",
    "#             except IOError:\n",
    "#                 print(\"Directory\", outpath, \"already exists\")\n",
    "\n",
    "#         directory = makedirectory()\n",
    "\n",
    "#         df = load_data() ## Applying function\n",
    "\n",
    "#         df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)\n",
    "\n",
    "#         loaddataillum = load_data_with_illum(*loaddata)\n",
    "\n",
    "#         loaddataillum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv')\n",
    "        \n",
    "        \n",
    "    \n",
    "#     return plist\n",
    "\n",
    "    \n",
    "# main(path, projdir, batchname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['CPBroadPhenixC1PlaneP1__C_BIN2_1P_2020-11-09T10_37_04-Measurement1',\n",
    "#  'CPBroadPhenixC1PlaneP2__C_BIN2_1P_2020-11-09T11_51_35-Measurement1',\n",
    "#  'CPBroadPhenixC1PlaneP3__C_BIN2_1P_2020-11-10T15_22_26-Measurement2',\n",
    "#  'CPBroadPhenixC1PlaneP4__C_BIN2_1P_2020-11-10T15_50_27-Measurement1',\n",
    "#  'CPBroadPhenixCP1__C_BIN2_3P_2020-10-08T15_18_17-Measurement3',\n",
    "#  'CPBroadPhenixCP2__C_BIN2_3P_2020-10-06T21_57_00-Measurement2',\n",
    "#  'CPBroadPhenixCP3__C_BIN2_3P_2020-10-07T14_39_07-Measurement1',\n",
    "#  'CPBroadPhenixCP4__C_BIN2_3P_2020-10-09T13_02_31-Measurement2',\n",
    "#  'CPBroadPhenixNC1PlaneP1__NC_BIN2_1P_2020-11-09T11_11_47-Measurement1',\n",
    "#  'CPBroadPhenixNC1PlaneP2__NC_BIN2_1P_2020-11-09T12_18_14-Measurement2',\n",
    "#  'CPBroadPhenixNC1PlaneP3__NC_BIN2_1P_2020-11-10T16_19_34-Measurement1',\n",
    "#  'CPBroadPhenixNC1PlaneP4__NC_BIN2_1P_2020-11-10T16_39_43-Measurement1',\n",
    "#  'CPBroadPhenixNCP1__NC_BIN2_3P_2020-10-08T14_06_33-Measurement3',\n",
    "#  'CPBroadPhenixNCP2__NC_BIN2_3P_2020-10-06T22_47_39-Measurement2',\n",
    "#  'CPBroadPhenixNCP3__NC_BIN2_3P_2020-10-07T13_03_27-Measurement2',\n",
    "#  'CPBroadPhenixNCP4__NC_BIN2_3P_2020-10-09T16_58_02-Measurement1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP/workspace/load_data_csv/2020_11_16_Scope1_PE/CPBroadPhenixC1PlaneP4 is created\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/bucket/projects'\n",
    "projdir = '2019_07_11_JUMP-CP'\n",
    "batchname = '2020_11_16_Scope1_PE'\n",
    "\n",
    "plist = [f for f in os.listdir(os.path.join(path, projdir, batchname, 'images'))][3]\n",
    "batchpath = os.path.join(path, projdir, batchname)\n",
    "fpath = os.path.join(path, projdir, batchname, 'images', plist, 'Images')\n",
    "plates = fpath.split('/')[-2].split('__')[0]\n",
    "outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, plates)\n",
    "\n",
    "\n",
    "def makedirectory():\n",
    "    try:\n",
    "        os.makedirs(outpath)\n",
    "        print(\"Directory\", outpath, \"is created\")\n",
    "    except IOError:\n",
    "        print(\"Directory\", outpath, \"already exists\")\n",
    "        \n",
    "makedirectory()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    lst=[]\n",
    "\n",
    "    for i, image in enumerate(os.listdir(fpath)):\n",
    "\n",
    "        imgpath = os.path.join(fpath, image)\n",
    "\n",
    "        if imgpath.endswith(\"tiff\"):\n",
    "\n",
    "            head, tail = os.path.split(imgpath)\n",
    "\n",
    "            lst.append(tail)\n",
    "            \n",
    "            \n",
    "    channels = {'ch1':\"OrigDNA\",\n",
    "    'ch2':\"OrigER\",\n",
    "    'ch3':\"OrigRNA\",\n",
    "    'ch4':\"OrigWGPhalloidin\",\n",
    "    'ch5':\"OrigMito\",\n",
    "    }\n",
    "\n",
    "    keys = list(channels.keys())\n",
    "    values = list(channels.values())\n",
    "\n",
    "\n",
    "    ch1 = [s for s in lst if 'ch1' in s]\n",
    "    ch2 = [s for s in lst if 'ch2' in s]\n",
    "    ch3 = [s for s in lst if 'ch3' in s]\n",
    "    ch4 = [s for s in lst if 'ch4' in s]\n",
    "    ch5 = [s for s in lst if 'ch5' in s]\n",
    "    \n",
    "\n",
    "    zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "    df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "    path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "    df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "    wellname = df['FileName_OrigDNA'].tolist()\n",
    "\n",
    "\n",
    "    pattern = re.compile(\"r(?P<row>\\d+)c(?P<column>\\d+)f(?P<site>\\d+)p(?P<zplane>\\d+)-ch(?P<channelnumber>\\d+)\")\n",
    "\n",
    "\n",
    "    ## apply this regrex to all the imagelist\n",
    "\n",
    "    match = [pattern.match(i) for i in wellname]\n",
    "    row = [r.group(\"row\") for r in match]\n",
    "    col= [c.group(\"column\") for c in match]\n",
    "    site= [f.group(\"site\") for f in match]\n",
    "    zplane= [int(s.group(\"zplane\")) for s in match]\n",
    "    channel= [ch.group(\"channelnumber\") for ch in match]\n",
    "\n",
    "    ## Defining Well names\n",
    "\n",
    "    rc = [r+c for r, c in zip(row, col)]\n",
    "\n",
    "    well_assignment= {'01' : \"A\",'02': \"B\",'03':\"C\",'04':\"D\",\n",
    "                      '05': \"E\",'06':\"F\",'07':\"G\",'08':\"H\",\n",
    "                      '09':\"I\",'10':\"J\",'11':\"K\",'12':\"L\",\n",
    "                      '13':\"M\",'14':\"N\",'15':\"O\",'16':\"P\"\n",
    "    }\n",
    "\n",
    "    well = [well_assignment.get(i[0:2])+i[2:] for i in rc]\n",
    "\n",
    "    df['Metadata_Well'] = well\n",
    "    df['Metadata_Site'] = site\n",
    "    df['Metadata_Plate'] = plates\n",
    "    df['Metadata_ZPlane'] = zplane\n",
    "    \n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "             'FileName_OrigER', 'PathName_OrigER',\n",
    "             'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "             'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "             'FileName_OrigMito', 'PathName_OrigMito',\n",
    "             'Metadata_Plate','Metadata_Well', \n",
    "            'Metadata_Site','Metadata_ZPlane']\n",
    "    \n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "df = load_data() ## Applying function\n",
    "\n",
    "df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_with_illum(*args):\n",
    "\n",
    "    df['FileName_IllumDNA'] = plates+'_IllumDNA.npy'\n",
    "    \n",
    "    df['PathName_IllumDNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumER'] = plates+'_IllumER.npy'\n",
    "    \n",
    "    df['PathName_IllumER'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumRNA'] = plates+'_IllumRNA.npy'\n",
    "    \n",
    "    df['PathName_IllumRNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumWGPhalloidin'] = plates+'_IllumWG-Phalloidin.npy'\n",
    "    \n",
    "    df['PathName_IllumWGPhalloidin'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumMito'] = plates+'_IllumMito.npy'\n",
    "    \n",
    "    df['PathName_IllumMito'] = os.path.join(batchpath, 'illum', plates)\n",
    "\n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "                 'FileName_OrigER', 'PathName_OrigER',\n",
    "                 'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "                 'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "                 'FileName_OrigMito', 'PathName_OrigMito',\n",
    "                 'Metadata_Plate','Metadata_Well', \n",
    "                'Metadata_Site', 'Metadata_ZPlane','FileName_IllumDNA', 'PathName_IllumDNA', \n",
    "                'FileName_IllumER', 'PathName_IllumER', \n",
    "                'FileName_IllumRNA', 'PathName_IllumRNA',\n",
    "                'FileName_IllumWGPhalloidin', 'PathName_IllumWGPhalloidin',\n",
    "                'FileName_IllumMito', 'PathName_IllumMito']\n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "loaddataillum = load_data_with_illum(*df)\n",
    "\n",
    "loaddataillum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
