{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import search\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/bucket/projects'\n",
    "projdir = '2019_07_11_JUMP-CP-pilots'\n",
    "batchname = '2020_11_06_Scope1_MolDev'\n",
    "subbatchname='C_BIN1_1Plane'\n",
    "batchpath =  os.path.join(path, projdir, batchname,subbatchname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fpath = '/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_PE/images/NC_BIN1_1Plane/CP Broad Phenix NC BIN1 1Plane P1__2020-11-11T11_43_07-Measurement 1/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/workspace/load_data_csv/2020_11_16_Scope1_PE/C_BIN1_1Plane/CP_Broad_Phenix_C_BIN1_1Plane_P1 already exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "plist = [f for f in os.listdir(os.path.join(path, projdir, batchname,'images', subbatchname))]\n",
    "\n",
    "for p in plist:\n",
    "\n",
    "\n",
    "    pl = p.split(\"__\")[0]\n",
    "\n",
    "    plates = '_'.join(pl.split())\n",
    "\n",
    "    outpath = os.path.join(path, projdir, 'workspace', 'load_data_csv', batchname, subbatchname, plates)\n",
    "\n",
    "\n",
    "\n",
    "    def makedirectory():\n",
    "\n",
    "        try:\n",
    "            os.makedirs(outpath)\n",
    "\n",
    "            print(\"Directory\", outpath, \"is created\")\n",
    "\n",
    "        except IOError:\n",
    "\n",
    "            print(\"Directory\", outpath, \"already exists\")\n",
    "\n",
    "    directory = makedirectory()\n",
    "\n",
    "\n",
    "    fpath = os.path.join(path, projdir, batchname,'images', subbatchname, p, 'Images')\n",
    "\n",
    "    df = load_data()\n",
    "\n",
    "    df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)\n",
    "\n",
    "    df_with_illum = load_data_with_illum()\n",
    "\n",
    "    df_with_illum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath='/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/2020_11_16_Scope1_PE/images/C_BIN1_3Planes/CP_Broad_Phenix_C_BIN1_P4/Images'\n",
    "\n",
    "\n",
    "plates = 'CP_Broad_Phenix_C_BIN1_P4'\n",
    "\n",
    "outpath = \"/home/ubuntu/bucket/projects/2019_07_11_JUMP-CP-pilots/workspace/load_data_csv/2020_11_16_Scope1_PE/C_BIN1_3Planes/CP_Broad_Phenix_C_BIN1_P4\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    lst=[]\n",
    "\n",
    "    for i, image in enumerate(os.listdir(fpath)):\n",
    "\n",
    "        imgpath = os.path.join(fpath, image)\n",
    "\n",
    "        if imgpath.endswith(\"tiff\"):\n",
    "\n",
    "            head, tail = os.path.split(imgpath)\n",
    "\n",
    "            lst.append(tail)\n",
    "            \n",
    "            \n",
    "    channels = {'ch1':\"OrigDNA\",\n",
    "    'ch2':\"OrigER\",\n",
    "    'ch3':\"OrigRNA\",\n",
    "    'ch4':\"OrigWGPhalloidin\",\n",
    "    'ch5':\"OrigMito\",\n",
    "    }\n",
    "\n",
    "    keys = list(channels.keys())\n",
    "    values = list(channels.values())\n",
    "\n",
    "\n",
    "    ch1 = [s for s in lst if 'ch1' in s]\n",
    "    ch2 = [s for s in lst if 'ch2' in s]\n",
    "    ch3 = [s for s in lst if 'ch3' in s]\n",
    "    ch4 = [s for s in lst if 'ch4' in s]\n",
    "    ch5 = [s for s in lst if 'ch5' in s]\n",
    "    \n",
    "\n",
    "    zippedlist = list(zip(ch1, ch2, ch3, ch4, ch5))\n",
    "\n",
    "    df = pd.DataFrame(zippedlist, columns=[\"FileName_\"+chname for chname in values])\n",
    "\n",
    "    path_columns = { c : fpath for c in [\"PathName_\"+chname for chname in values]}\n",
    "\n",
    "    df = df.assign(**path_columns)\n",
    "\n",
    "\n",
    "    wellname = df['FileName_OrigDNA'].tolist()\n",
    "\n",
    "\n",
    "    pattern = re.compile(\"r(?P<row>\\d+)c(?P<column>\\d+)f(?P<site>\\d+)p(?P<zplane>\\d+)-ch(?P<channelnumber>\\d+)\")\n",
    "\n",
    "\n",
    "    ## apply this regrex to all the imagelist\n",
    "\n",
    "    match = [pattern.match(i) for i in wellname]\n",
    "    row = [r.group(\"row\") for r in match]\n",
    "    col= [c.group(\"column\") for c in match]\n",
    "    site= [f.group(\"site\") for f in match]\n",
    "    zplane= [int(s.group(\"zplane\")) for s in match]\n",
    "    channel= [ch.group(\"channelnumber\") for ch in match]\n",
    "\n",
    "    ## Defining Well names\n",
    "\n",
    "    rc = [r+c for r, c in zip(row, col)]\n",
    "\n",
    "    well_assignment= {'01' : \"A\",'02': \"B\",'03':\"C\",'04':\"D\",\n",
    "                      '05': \"E\",'06':\"F\",'07':\"G\",'08':\"H\",\n",
    "                      '09':\"I\",'10':\"J\",'11':\"K\",'12':\"L\",\n",
    "                      '13':\"M\",'14':\"N\",'15':\"O\",'16':\"P\"\n",
    "    }\n",
    "\n",
    "    well = [well_assignment.get(i[0:2])+i[2:] for i in rc]\n",
    "\n",
    "    df['Metadata_Well'] = well\n",
    "    df['Metadata_Site'] = site\n",
    "    df['Metadata_Plate'] = plates\n",
    "    df['Metadata_ZPlane'] = zplane\n",
    "    \n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "             'FileName_OrigER', 'PathName_OrigER',\n",
    "             'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "             'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "             'FileName_OrigMito', 'PathName_OrigMito',\n",
    "             'Metadata_Plate','Metadata_Well', \n",
    "            'Metadata_Site','Metadata_ZPlane']\n",
    "    \n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "df = load_data() \n",
    "\n",
    "df.to_csv(outpath + \"/\" + 'load_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data_with_illum():\n",
    "\n",
    "    df['FileName_IllumDNA'] = plates+'_IllumDNA.npy'\n",
    "    \n",
    "    df['PathName_IllumDNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumER'] = plates+'_IllumER.npy'\n",
    "    \n",
    "    df['PathName_IllumER'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumRNA'] = plates+'_IllumRNA.npy'\n",
    "    \n",
    "    df['PathName_IllumRNA'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumWGPhalloidin'] = plates+'_IllumWGPhalloidin.npy'\n",
    "    \n",
    "    df['PathName_IllumWGPhalloidin'] = os.path.join(batchpath, 'illum', plates)\n",
    "    \n",
    "    df['FileName_IllumMito'] = plates+'_IllumMito.npy'\n",
    "    \n",
    "    df['PathName_IllumMito'] = os.path.join(batchpath, 'illum', plates)\n",
    "\n",
    "    colnames = ['FileName_OrigDNA', 'PathName_OrigDNA',\n",
    "                 'FileName_OrigER', 'PathName_OrigER',\n",
    "                 'FileName_OrigRNA', 'PathName_OrigRNA',\n",
    "                 'FileName_OrigWGPhalloidin', 'PathName_OrigWGPhalloidin', \n",
    "                 'FileName_OrigMito', 'PathName_OrigMito',\n",
    "                 'Metadata_Plate','Metadata_Well', \n",
    "                'Metadata_Site', 'Metadata_ZPlane','FileName_IllumDNA', 'PathName_IllumDNA', \n",
    "                'FileName_IllumER', 'PathName_IllumER', \n",
    "                'FileName_IllumRNA', 'PathName_IllumRNA',\n",
    "                'FileName_IllumWGPhalloidin', 'PathName_IllumWGPhalloidin',\n",
    "                'FileName_IllumMito', 'PathName_IllumMito']\n",
    "    \n",
    "    return df.reindex(columns=colnames)\n",
    "\n",
    "illum = load_data_with_illum()\n",
    "\n",
    "illum.to_csv(outpath + \"/\" + 'load_data_with_illum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
